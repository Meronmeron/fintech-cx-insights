"""
Database Manager for Ethiopian Banking Apps Analysis
Supports Oracle XE and PostgreSQL with comprehensive data operations
"""

import pandas as pd
from sqlalchemy import create_engine, text
from sqlalchemy.exc import SQLAlchemyError
import logging
from typing import Optional, Dict, List, Any
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class DatabaseManager:
    """Database manager for Oracle XE with PostgreSQL fallback"""
    
    def __init__(self, use_oracle: bool = True):
        self.use_oracle = use_oracle
        self.engine = None
        self.connection = None
        self.connected = False
        self.db_type = "Oracle XE" if use_oracle else "PostgreSQL"
        
    def connect(self) -> bool:
        """Establish database connection"""
        try:
            if self.use_oracle:
                return self._connect_oracle()
            else:
                return self._connect_postgres()
        except Exception as e:
            logger.error(f"Database connection failed: {e}")
            return False
    
    def _connect_oracle(self) -> bool:
        """Connect to Oracle XE using modern oracledb driver"""
        try:
            # Try to import Oracle dependencies
            try:
                import oracledb
            except ImportError:
                logger.error("oracledb not installed. Please install: pip install oracledb")
                return False
            
            from config.database_config import ORACLE_CONNECTION_STRING
            
            self.engine = create_engine(
                ORACLE_CONNECTION_STRING,
                echo=False,
                pool_pre_ping=True,
                pool_recycle=3600
            )
            
            # Test connection
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT 1 FROM DUAL"))
                logger.info("✅ Oracle XE connection established")
                self.connected = True
                return True
                
        except Exception as e:
            logger.error(f"Oracle connection failed: {e}")
            return False
    
    def _connect_postgres(self) -> bool:
        """Connect to PostgreSQL (fallback)"""
        try:
            # Try to import PostgreSQL dependencies
            try:
                import psycopg2
            except ImportError:
                logger.error("psycopg2 not installed. Please install: pip install psycopg2-binary")
                return False
            
            from config.database_config import POSTGRES_CONNECTION_STRING
            
            self.engine = create_engine(
                POSTGRES_CONNECTION_STRING,
                echo=False,
                pool_pre_ping=True
            )
            
            # Test connection
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT 1"))
                logger.info("✅ PostgreSQL connection established")
                self.connected = True
                return True
                
        except Exception as e:
            logger.error(f"PostgreSQL connection failed: {e}")
            return False
    
    def create_tables(self) -> bool:
        """Create database tables if they don't exist"""
        try:
            if self.use_oracle:
                return self._create_oracle_tables()
            else:
                return self._create_postgres_tables()
        except Exception as e:
            logger.error(f"Table creation failed: {e}")
            return False
    
    def _create_oracle_tables(self) -> bool:
        """Create Oracle tables"""
        try:
            with self.engine.connect() as conn:
                # Check if tables already exist
                check_banks_query = text("""
                    SELECT COUNT(*) as count FROM user_tables WHERE table_name = 'BANKS'
                """)
                
                check_reviews_query = text("""
                    SELECT COUNT(*) as count FROM user_tables WHERE table_name = 'REVIEWS'
                """)
                
                banks_exists = conn.execute(check_banks_query).fetchone()[0] > 0
                reviews_exists = conn.execute(check_reviews_query).fetchone()[0] > 0
                
                if banks_exists and reviews_exists:
                    logger.info("✅ Tables already exist")
                    return True
                
                # Create Banks table if it doesn't exist
                if not banks_exists:
                    banks_sql = """
                    CREATE TABLE banks (
                        bank_id         NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                        bank_name       VARCHAR2(100) NOT NULL UNIQUE,
                        bank_code       VARCHAR2(10) NOT NULL UNIQUE,
                        app_package     VARCHAR2(100),
                        established_date DATE,
                        headquarters    VARCHAR2(100),
                        created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                    """
                    
                    try:
                        conn.execute(text(banks_sql))
                        logger.info("✅ Banks table created")
                    except Exception as e:
                        if "already exists" in str(e).lower() or "name is already used" in str(e).lower():
                            logger.info("Banks table already exists")
                        else:
                            raise e
                
                # Create Reviews table if it doesn't exist
                if not reviews_exists:
                    reviews_sql = """
                    CREATE TABLE reviews (
                        review_id           NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
                        bank_id             NUMBER NOT NULL,
                        review_text         CLOB NOT NULL,
                        rating              NUMBER(2,1) CHECK (rating BETWEEN 1.0 AND 5.0),
                        review_date         DATE,
                        reviewer_name       VARCHAR2(100),
                        app_version         VARCHAR2(20),
                        helpful_count       NUMBER DEFAULT 0,
                        review_length       NUMBER,
                        
                        -- Sentiment Analysis Results
                        vader_compound      NUMBER(4,3),
                        vader_positive      NUMBER(4,3),
                        vader_neutral       NUMBER(4,3),
                        vader_negative      NUMBER(4,3),
                        vader_label         VARCHAR2(10),
                        
                        textblob_polarity   NUMBER(4,3),
                        textblob_subjectivity NUMBER(4,3),
                        textblob_label      VARCHAR2(10),
                        
                        distilbert_positive NUMBER(4,3),
                        distilbert_negative NUMBER(4,3),
                        distilbert_label    VARCHAR2(10),
                        distilbert_confidence NUMBER(4,3),
                        
                        ensemble_label      VARCHAR2(10),
                        ensemble_confidence NUMBER(4,3),
                        
                        -- Metadata
                        scraped_date        TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        processed_date      TIMESTAMP,
                        data_source         VARCHAR2(50) DEFAULT 'Google Play Store',
                        
                        -- Constraints (modified for system user)
                        CONSTRAINT chk_sentiment_labels CHECK (
                            (vader_label IS NULL OR vader_label IN ('Positive', 'Negative', 'Neutral')) AND
                            (textblob_label IS NULL OR textblob_label IN ('Positive', 'Negative', 'Neutral')) AND
                            (distilbert_label IS NULL OR distilbert_label IN ('Positive', 'Negative', 'Neutral')) AND
                            (ensemble_label IS NULL OR ensemble_label IN ('Positive', 'Negative', 'Neutral'))
                        )
                    )
                    """
                    
                    try:
                        conn.execute(text(reviews_sql))
                        logger.info("✅ Reviews table created")
                    except Exception as e:
                        if "already exists" in str(e).lower() or "name is already used" in str(e).lower():
                            logger.info("Reviews table already exists")
                        else:
                            raise e
                
                # Add foreign key constraint separately (if not exists)
                try:
                    fk_sql = """
                    ALTER TABLE reviews 
                    ADD CONSTRAINT fk_reviews_bank 
                    FOREIGN KEY (bank_id) REFERENCES banks(bank_id)
                    """
                    conn.execute(text(fk_sql))
                    logger.info("✅ Foreign key constraint added")
                except Exception as e:
                    if "already exists" in str(e).lower() or "name is already used" in str(e).lower():
                        logger.info("Foreign key constraint already exists")
                    else:
                        logger.warning(f"Foreign key constraint creation failed: {e}")
                
                # Create indexes if they don't exist
                indexes = [
                    ("idx_reviews_bank_id", "CREATE INDEX idx_reviews_bank_id ON reviews(bank_id)"),
                    ("idx_reviews_rating", "CREATE INDEX idx_reviews_rating ON reviews(rating)"),
                    ("idx_reviews_date", "CREATE INDEX idx_reviews_date ON reviews(review_date)"),
                    ("idx_reviews_sentiment", "CREATE INDEX idx_reviews_sentiment ON reviews(ensemble_label)")
                ]
                
                for idx_name, idx_sql in indexes:
                    try:
                        conn.execute(text(idx_sql))
                        logger.info(f"✅ Index {idx_name} created")
                    except Exception as e:
                        if "already exists" in str(e).lower() or "name is already used" in str(e).lower():
                            logger.info(f"Index {idx_name} already exists")
                        else:
                            logger.warning(f"Index {idx_name} creation failed: {e}")
                
                conn.commit()
                return True
                
        except Exception as e:
            logger.error(f"Oracle table creation failed: {e}")
            return False
    
    def _create_postgres_tables(self) -> bool:
        """Create PostgreSQL tables"""
        try:
            with self.engine.connect() as conn:
                # Create Banks table
                banks_sql = """
                CREATE TABLE IF NOT EXISTS banks (
                    bank_id         SERIAL PRIMARY KEY,
                    bank_name       VARCHAR(100) NOT NULL UNIQUE,
                    bank_code       VARCHAR(10) NOT NULL UNIQUE,
                    app_package     VARCHAR(100),
                    established_date DATE,
                    headquarters    VARCHAR(100),
                    created_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
                """
                
                # Create Reviews table
                reviews_sql = """
                CREATE TABLE IF NOT EXISTS reviews (
                    review_id           SERIAL PRIMARY KEY,
                    bank_id             INTEGER NOT NULL REFERENCES banks(bank_id),
                    review_text         TEXT NOT NULL,
                    rating              DECIMAL(2,1) CHECK (rating BETWEEN 1.0 AND 5.0),
                    review_date         DATE,
                    reviewer_name       VARCHAR(100),
                    app_version         VARCHAR(20),
                    helpful_count       INTEGER DEFAULT 0,
                    review_length       INTEGER,
                    
                    -- Sentiment Analysis Results
                    vader_compound      DECIMAL(4,3),
                    vader_positive      DECIMAL(4,3),
                    vader_neutral       DECIMAL(4,3),
                    vader_negative      DECIMAL(4,3),
                    vader_label         VARCHAR(10),
                    
                    textblob_polarity   DECIMAL(4,3),
                    textblob_subjectivity DECIMAL(4,3),
                    textblob_label      VARCHAR(10),
                    
                    distilbert_positive DECIMAL(4,3),
                    distilbert_negative DECIMAL(4,3),
                    distilbert_label    VARCHAR(10),
                    distilbert_confidence DECIMAL(4,3),
                    
                    ensemble_label      VARCHAR(10),
                    ensemble_confidence DECIMAL(4,3),
                    
                    -- Metadata
                    scraped_date        TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed_date      TIMESTAMP,
                    data_source         VARCHAR(50) DEFAULT 'Google Play Store',
                    
                    -- Constraints
                    CONSTRAINT chk_sentiment_labels CHECK (
                        vader_label IN ('Positive', 'Negative', 'Neutral') AND
                        textblob_label IN ('Positive', 'Negative', 'Neutral') AND
                        distilbert_label IN ('Positive', 'Negative', 'Neutral') AND
                        ensemble_label IN ('Positive', 'Negative', 'Neutral')
                    )
                )
                """
                
                # Execute table creation
                conn.execute(text(banks_sql))
                conn.execute(text(reviews_sql))
                
                # Create indexes
                indexes = [
                    "CREATE INDEX IF NOT EXISTS idx_reviews_bank_id ON reviews(bank_id)",
                    "CREATE INDEX IF NOT EXISTS idx_reviews_rating ON reviews(rating)",
                    "CREATE INDEX IF NOT EXISTS idx_reviews_date ON reviews(review_date)",
                    "CREATE INDEX IF NOT EXISTS idx_reviews_sentiment ON reviews(ensemble_label)"
                ]
                
                for idx_sql in indexes:
                    conn.execute(text(idx_sql))
                
                conn.commit()
                logger.info("✅ PostgreSQL tables and indexes created")
                return True
                
        except Exception as e:
            logger.error(f"PostgreSQL table creation failed: {e}")
            return False
    
    def insert_banks_data(self) -> bool:
        """Insert Ethiopian banks data"""
        banks_data = [
            {
                'bank_name': 'Commercial Bank of Ethiopia',
                'bank_code': 'CBE',
                'app_package': 'com.cbe.mobile',
                'established_date': '1963-01-01',
                'headquarters': 'Addis Ababa'
            },
            {
                'bank_name': 'Dashen Bank',
                'bank_code': 'DASH',
                'app_package': 'com.dashen.mobile',
                'established_date': '1995-09-20',
                'headquarters': 'Addis Ababa'
            },
            {
                'bank_name': 'Bank of Abyssinia',
                'bank_code': 'BOA',
                'app_package': 'com.boa.mobile',
                'established_date': '1996-02-15',
                'headquarters': 'Addis Ababa'
            }
        ]
        
        try:
            # Check if banks already exist
            existing_banks = self.execute_query("SELECT bank_name FROM banks")
            if not existing_banks.empty:
                logger.info("Banks data already exists, skipping insertion")
                return True
            
            # Use Oracle-compatible insertion method
            if self.use_oracle:
                return self._insert_banks_oracle(banks_data)
            else:
                df = pd.DataFrame(banks_data)
                df.to_sql('banks', self.engine, if_exists='append', index=False, method='multi')
                logger.info(f"✅ Inserted {len(banks_data)} banks")
                return True
            
        except Exception as e:
            logger.error(f"Failed to insert banks data: {e}")
            return False
    
    def _insert_banks_oracle(self, banks_data: List[Dict]) -> bool:
        """Insert banks data using Oracle-compatible method"""
        try:
            with self.engine.connect() as conn:
                for bank in banks_data:
                    # Check if bank already exists
                    check_query = text("SELECT COUNT(*) as count FROM banks WHERE bank_name = :bank_name")
                    result = conn.execute(check_query, {"bank_name": bank['bank_name']})
                    count = result.fetchone()[0]
                    
                    if count == 0:
                        # Insert bank using individual INSERT statements
                        insert_query = text("""
                            INSERT INTO banks (bank_name, bank_code, app_package, established_date, headquarters)
                            VALUES (:bank_name, :bank_code, :app_package, TO_DATE(:established_date, 'YYYY-MM-DD'), :headquarters)
                        """)
                        
                        conn.execute(insert_query, bank)
                        logger.info(f"✅ Inserted bank: {bank['bank_name']}")
                    else:
                        logger.info(f"Bank already exists: {bank['bank_name']}")
                
                conn.commit()
                logger.info(f"✅ Banks data insertion completed")
                return True
                
        except Exception as e:
            logger.error(f"Oracle banks insertion failed: {e}")
            return False
    
    def insert_reviews_data(self, df: pd.DataFrame) -> bool:
        """Insert reviews data from DataFrame"""
        try:
            # Get bank mappings
            bank_mapping = self.get_bank_mapping()
            
            if not bank_mapping:
                logger.error("No bank mapping available. Ensure banks are inserted first.")
                return False
            
            # Prepare reviews data
            df_processed = df.copy()
            df_processed['bank_id'] = df_processed['bank'].map(bank_mapping)
            
            # Drop rows with no bank mapping
            unmapped_banks = df_processed[df_processed['bank_id'].isna()]['bank'].unique()
            if len(unmapped_banks) > 0:
                logger.warning(f"Unmapped banks: {unmapped_banks}")
                df_processed = df_processed.dropna(subset=['bank_id'])
            
            # Rename columns to match database schema FIRST
            column_mapping = {
                'review': 'review_text',  # Map 'review' column to 'review_text'
                'date': 'review_date'
            }
            df_processed.rename(columns=column_mapping, inplace=True)
            
            # Select relevant columns for database
            db_columns = [
                'bank_id', 'review_text', 'rating', 'review_date', 'reviewer_name',
                'vader_compound', 'vader_positive', 'vader_neutral', 'vader_negative', 'vader_label',
                'textblob_polarity', 'textblob_subjectivity', 'textblob_label',
                'distilbert_positive', 'distilbert_negative', 'distilbert_label', 'distilbert_confidence',
                'ensemble_label', 'ensemble_confidence'
            ]
            
            # Filter available columns
            available_columns = [col for col in db_columns if col in df_processed.columns]
            df_insert = df_processed[available_columns].copy()
            
            # Handle missing columns with defaults
            for col in db_columns:
                if col not in df_insert.columns:
                    if 'vader' in col or 'textblob' in col or 'distilbert' in col or 'ensemble' in col:
                        if 'label' in col:
                            df_insert[col] = 'Neutral'
                        else:
                            df_insert[col] = 0.0
                    else:
                        df_insert[col] = None
            
            # Add metadata
            if 'review_text' in df_insert.columns:
                df_insert['review_length'] = df_insert['review_text'].str.len()
            df_insert['processed_date'] = datetime.now()
            
            # Clean data before insertion - handle NULL review_text specifically
            df_insert = df_insert.where(pd.notnull(df_insert), None)
            
            # Remove rows where review_text is NULL (required field)
            initial_count = len(df_insert)
            df_insert = df_insert.dropna(subset=['review_text'])
            final_count = len(df_insert)
            
            if initial_count != final_count:
                logger.warning(f"Removed {initial_count - final_count} rows with NULL review_text")
            
            if len(df_insert) == 0:
                logger.error("No valid review data to insert after cleaning")
                return False
            
            # Use Oracle-compatible insertion method
            if self.use_oracle:
                return self._insert_reviews_oracle(df_insert)
            else:
                # Insert data in chunks for PostgreSQL
                chunk_size = 100
                total_inserted = 0
                
                for i in range(0, len(df_insert), chunk_size):
                    chunk = df_insert.iloc[i:i+chunk_size]
                    chunk.to_sql('reviews', self.engine, if_exists='append', index=False, method='multi')
                    total_inserted += len(chunk)
                    logger.info(f"Inserted chunk {i//chunk_size + 1}: {len(chunk)} reviews")
                
                logger.info(f"✅ Successfully inserted {total_inserted} reviews")
                return True
            
        except Exception as e:
            logger.error(f"Failed to insert reviews data: {e}")
            return False
    
    def _insert_reviews_oracle(self, df_insert: pd.DataFrame) -> bool:
        """Insert reviews data using Oracle-compatible method"""
        try:
            with self.engine.connect() as conn:
                # Convert DataFrame to list of dictionaries for individual inserts
                records = df_insert.to_dict('records')
                chunk_size = 50  # Smaller chunks for Oracle
                total_inserted = 0
                
                for i in range(0, len(records), chunk_size):
                    chunk = records[i:i+chunk_size]
                    
                    for record in chunk:
                        # Handle None values and data types for Oracle
                        processed_record = {}
                        for key, value in record.items():
                            if pd.isna(value) or value is None:
                                processed_record[key] = None
                            elif key == 'review_date' and value is not None:
                                # Handle date conversion
                                if isinstance(value, str):
                                    processed_record[key] = value
                                else:
                                    processed_record[key] = str(value)
                            else:
                                processed_record[key] = value
                        
                        # Create dynamic INSERT statement
                        columns = list(processed_record.keys())
                        placeholders = [f":{col}" for col in columns]
                        
                        insert_query = text(f"""
                            INSERT INTO reviews ({', '.join(columns)})
                            VALUES ({', '.join(placeholders)})
                        """)
                        
                        try:
                            conn.execute(insert_query, processed_record)
                            total_inserted += 1
                        except Exception as e:
                            logger.warning(f"Failed to insert individual record: {e}")
                            continue
                    
                    # Commit after each chunk
                    conn.commit()
                    logger.info(f"Inserted chunk {i//chunk_size + 1}: {len(chunk)} reviews (Total: {total_inserted})")
                
                logger.info(f"✅ Successfully inserted {total_inserted} reviews using Oracle method")
                return True
                
        except Exception as e:
            logger.error(f"Oracle reviews insertion failed: {e}")
            return False
    
    def get_bank_mapping(self) -> Dict[str, int]:
        """Get bank name to ID mapping"""
        try:
            query = "SELECT bank_id, bank_name FROM banks"
            df = pd.read_sql(query, self.engine)
            
            # Create mapping
            mapping = {}
            for _, row in df.iterrows():
                bank_name = row['bank_name']
                bank_id = row['bank_id']
                
                # Add various name variations
                mapping[bank_name] = bank_id
                mapping[bank_name.lower()] = bank_id
                
                # Specific mappings for our data
                if 'Commercial' in bank_name:
                    mapping['Commercial Bank of Ethiopia'] = bank_id
                elif 'Dashen' in bank_name:
                    mapping['Dashen Bank'] = bank_id
                elif 'Abyssinia' in bank_name:
                    mapping['Bank of Abyssinia'] = bank_id
            
            return mapping
            
        except Exception as e:
            logger.error(f"Failed to get bank mapping: {e}")
            return {}
    
    def execute_query(self, query: str) -> pd.DataFrame:
        """Execute SELECT query and return DataFrame"""
        try:
            return pd.read_sql(query, self.engine)
        except Exception as e:
            logger.error(f"Query execution failed: {e}")
            return pd.DataFrame()
    
    def get_database_stats(self) -> Dict[str, Any]:
        """Get database statistics"""
        try:
            stats = {}
            
            # Count tables
            banks_count = pd.read_sql("SELECT COUNT(*) as count FROM banks", self.engine)
            reviews_count = pd.read_sql("SELECT COUNT(*) as count FROM reviews", self.engine)
            
            stats['banks_count'] = banks_count.iloc[0]['count']
            stats['reviews_count'] = reviews_count.iloc[0]['count']
            
            # Reviews by bank
            bank_reviews = pd.read_sql("""
                SELECT b.bank_name, COUNT(r.review_id) as review_count
                FROM banks b
                LEFT JOIN reviews r ON b.bank_id = r.bank_id
                GROUP BY b.bank_name
            """, self.engine)
            
            stats['reviews_by_bank'] = bank_reviews.to_dict('records')
            
            # Sentiment distribution
            sentiment_dist = pd.read_sql("""
                SELECT ensemble_label, COUNT(*) as count
                FROM reviews
                WHERE ensemble_label IS NOT NULL
                GROUP BY ensemble_label
            """, self.engine)
            
            stats['sentiment_distribution'] = sentiment_dist.to_dict('records')
            
            return stats
            
        except Exception as e:
            logger.error(f"Failed to get database stats: {e}")
            return {}
    
    def verify_data_integrity(self) -> Dict[str, bool]:
        """Verify data integrity and constraints"""
        try:
            integrity_checks = {}
            
            # Check foreign key integrity
            fk_check = pd.read_sql("""
                SELECT COUNT(*) as orphaned_reviews
                FROM reviews r
                LEFT JOIN banks b ON r.bank_id = b.bank_id
                WHERE b.bank_id IS NULL
            """, self.engine)
            
            integrity_checks['foreign_key_integrity'] = fk_check.iloc[0]['orphaned_reviews'] == 0
            
            # Check rating constraints
            rating_check = pd.read_sql("""
                SELECT COUNT(*) as invalid_ratings
                FROM reviews
                WHERE rating < 1.0 OR rating > 5.0
            """, self.engine)
            
            integrity_checks['rating_constraints'] = rating_check.iloc[0]['invalid_ratings'] == 0
            
            # Check sentiment label constraints
            sentiment_check = pd.read_sql("""
                SELECT COUNT(*) as invalid_sentiments
                FROM reviews
                WHERE ensemble_label NOT IN ('Positive', 'Negative', 'Neutral')
                AND ensemble_label IS NOT NULL
            """, self.engine)
            
            integrity_checks['sentiment_constraints'] = sentiment_check.iloc[0]['invalid_sentiments'] == 0
            
            return integrity_checks
            
        except Exception as e:
            logger.error(f"Data integrity check failed: {e}")
            return {}
    
    def close(self):
        """Close database connection"""
        if self.engine:
            self.engine.dispose()
            self.connected = False
            logger.info(f"{self.db_type} connection closed") 